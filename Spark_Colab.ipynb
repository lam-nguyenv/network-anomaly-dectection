{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_Colab",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamvng/network-anomaly-dectection/blob/tuan_edit/Spark_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O1w4UT7QvC9R"
      },
      "source": [
        "# Sử dụng KMeans triển khai trên Pyspark để phát hiện bất thường trong mạng\n",
        "*Thái Bá Tuân, Nguyễn Văn Lâm, Phạm Anh Đức - PFIEV K60*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2xNfQcxSRKbb"
      },
      "source": [
        "## **0. Giới thiệu và trình tự bài báo cáo**\n",
        "Bài báo cáo được trình bày thành ba phần như sau:\n",
        "\n",
        "**1.   Giới thiệu mục tiêu và bộ dữ liệu**\n",
        "\n",
        "*   Giới thiệu bài toán Anomalies Detection\n",
        "*   Bộ dữ liệu `kddcup 1999`\n",
        "\n",
        "**2.   Thuật toán KMeans**\n",
        "\n",
        "*   Giới thiệu\n",
        "*   Thuật toán\n",
        "\n",
        "**3.   Triển khai KMeans bằng Pyspark**\n",
        "\n",
        "*   Khảo sát và tiền xử lý bộ dữ liệu\n",
        "*   Chạy KMeans với 2 clusters và nhận xét\n",
        "*   Lựa chọn số clusters phù hợp\n",
        "*   Xác định Anomalies với số cụm đã chọn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "owDdaqoVUzBK"
      },
      "source": [
        "## **1. Giới thiệu mục tiêu và bộ dữ liệu**\n",
        "\n",
        "### ***1.1. Mục tiêu bài toán***\n",
        "\n",
        "Với dữ liệu đầu vào là một tập các log files ghi lại các kết nối của một hệ thống nhất định, ta cần đưa ra dự đoán xem kết nối đó có phải bất thường hay không (mass ping, quét cổng hàng loạt...)\n",
        "\n",
        "\n",
        "*   **Input**: Log file ghi lại các kết nối tới hệ thống, bao gồm các thông tin như IP, giao thức kết nối, kích thước gói tin...\n",
        "*   **Output**: Dự đoán các kết nối đó có phải kết nối bất thường (brute force mật khẩu, quét cổng hàng loạt, mass ping...) hay không.\n",
        "\n",
        "### ***1.2. Giới thiệu bộ dữ liệu KDD 1999***\n",
        "Bộ dữ liệu được nhóm sử dụng cho bài báo cáo là [KDD Cup 1999](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html), trong đó, bao gồm các file như sau:\n",
        "\n",
        "*   [kddcup.data.gz](http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz): Bộ dữ liệu bản đầy đủ. Kích thước file nén là 18 MB, khi giải nén ra sẽ thành 743 MB.\n",
        "*   [kddcup.data_10_percent.gz](http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz): Bộ dữ liệu có kích thước bằng 10% bản đầy đủ. Kích thước file nén là 2 MB, khi giải nén ra sẽ thành 75 MB.\n",
        "*   [kddcup.names](http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names): Chứa tên và kiểu dữ liệu của mỗi trường có trong bộ dữ liệu. Tệp dữ liệu `kddcup.data.gz` không có sẵn những thông tin về tên trường (*header*) tên ta có thể thêm chúng vào dataset ở bước tiền xử lý.\n",
        "\n",
        "Bộ dữ liệu `kddcup.data.gz` được lưu dưới định dạng `csv`, bao gồm 4,9 triệu bản ghi, mỗi bản ghi bao \n",
        "Để tăng tốc độ load và xử lý dữ liệu, nhóm sẽ triển khai thuật toán trên tập dữ liệu 10%, có kích thước 75 MB, thay vì bộ dữ liệu gốc có kích thước 743 MB.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YXtOEFus6c7Y"
      },
      "source": [
        "## **2. Thuật toán KMeans**\n",
        " \n",
        "## ***2.1. Giới thiệu***\n",
        "Phân cụm là một loại hình học không giám sát (unsupervised learning) điển hình. Mục đích là làm thể nào để phân dữ liệu thành các cụm (cluster) khác nhau sao cho dữ liệu trong cùng một cụm có tính chất giống nhau.\n",
        "\n",
        "Phân cụm K-Means là một thuật toán phân cụm đơn giản và được sử dụng rộng rãi. Cho giá trị của k, nó cố gắng xây dựng các cụm k từ các mẫu trong bộ dữ liệu. Do đó, k là một siêu tham số của mô hình. Giá trị đúng của k không dễ xác định, vì nó phụ thuộc nhiều vào tập dữ liệu và cách dữ liệu được thực hiện.\n",
        "\n",
        "Để kiểm tra sự giống nhau giữa hai điểm dữ liệu bất kỳ, K-mean yêu cầu định nghĩa về khoảng cách giữa các điểm dữ liệu. Khoảng cách là gì? Đó là một giá trị cho biết mức độ gần nhau của hai điểm dữ liệu trong không gian của chúng. Đặc biệt, khi các điểm dữ liệu nằm trong một không gian hai chiều, khoảng cách Euclide là một lựa chọn tốt của hàm khoảng cách và được thư viện MLLIB hỗ trợ.\n",
        "\n",
        "Trong K-mean, cụm là một nhóm các điểm, với một thực thể đại diện được gọi là centroid. Một centroid cũng là một điểm trong không gian dữ liệu: trung tâm của tất cả các điểm tạo nên cụm. Nó được định nghĩa là trung bình số học của các điểm. Nói chung, khi làm việc với K-means-clustering, mỗi mẫu dữ liệu được biểu diễn trong một vectơ số d chiều, do đó dễ dàng hơn để xác định hàm khoảng cách phù hợp. Kết quả là, trong một số ứng dụng, dữ liệu gốc phải được chuyển đổi thành một biểu diễn khác, để phù hợp với yêu cầu của phương tiện K.\n",
        "### ***2.1.2   \bThuật toán K-means***\n",
        "**Đầu vào:** Dữ liệu X và số lượng cluster cần tìm k.\n",
        "\n",
        "**Đầu ra:**  Các center M và label vector cho từng điểm dữ liệu Y\n",
        "\n",
        "\n",
        "1.   Chọn K điểm bất kỳ làm các center ban đầu.\n",
        "2.   Phân mỗi điểm dữ liệu vào cluster có center gần nó nhất.\n",
        "3.   Nếu việc gán dữ liệu vào từng cluster ở bước 2 không thay đổi so với vòng lặp trước nó thì ta dừng thuật toán.\n",
        "4.   Cập nhật center cho từng cluster bằng cách lấy trung bình cộng của tất các các điểm dữ liệu đã được gán vào cluster đó sau bước 2.\n",
        "5.   Quay lại bước 2.\n",
        "\n",
        "Chúng ta cũng có thể chấm dứt thuật toán khi nó đạt đến số lần lặp xác định, mang lại kết quả gần đúng. Từ mã giả của thuật toán, chúng ta có thể thấy rằng kết quả phân cụm có nghĩa là **K** có thể nhạy cảm với thứ tự mà các mẫu dữ liệu trong tập dữ liệu được khám phá. Một thực hành hợp lý sẽ là chạy phân tích nhiều lần, sắp xếp ngẫu nhiên các đối tượng; sau đó, tính trung bình các trung tâm cụm của các lần chạy đó và nhập các trung tâm làm trung tâm ban đầu cho một lần phân tích cuối cùng.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NVrSx7hgvOWQ"
      },
      "source": [
        "## **3. Triển khai KMeans bằng Pyspark**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Đầu tiên, cần kích hoạt [Google Colab](https://colab.research.google.com/) bằng tài khoản Google. Các file sau đó sẽ được mở dưới dạng Jupyter Notebook.\n",
        "\n",
        "Sau đó ta có thể tiến hành cài đặt Pyspark trực tiếp qua Google Colab thông qua thư viện `findspark`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y4GIsY78a5aB",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HxVglWaCvau_"
      },
      "source": [
        "Cài đặt các biến môi trường:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vyoxuUMXcJe_",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8566ZZbocK3S",
        "outputId": "b1fbf505-54ce-4363-a9f6-fc800e4dcdf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
            "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sig1SPHe0fvd"
      },
      "source": [
        "Kết nối tới tài khoản Drive, cho phép sử dụng Drive API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h1hQidzrcjb2",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Tạo PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "THx7RX5j2-Ex"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Lấy link bộ dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QX0BhIO8g1T9",
        "outputId": "a6cbae22-18ed-4a1d-aee8-93cc7291cbb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "link = \"https://drive.google.com/open?id=1wOl76pErCKeFwFnPRk_u-56STpqva2JQ\" # You may change your URL here\n",
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1wOl76pErCKeFwFnPRk_u-56STpqva2JQ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LA0d3r9X030o"
      },
      "source": [
        "Tạo SparkSession và lấy bộ dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hEZ4frfRhJW-",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('kddcup.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGQrpMe9hUvG",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Anomalies Detection\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dC1T_C4q4q5w"
      },
      "source": [
        "Bộ dữ liệu gốc được lưu dưới dạng file `csv` nhưng không có header. Vì vậy, ta cần tự thêm header vào các trường trong `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cRsnxsTphuSg",
        "colab": {}
      },
      "source": [
        "dataWithoutHeader = spark.read.option(\"inferSchema\", True).option(\"header\", False).csv(\"kddcup.csv\")\n",
        "data = dataWithoutHeader.toDF(\"duration\", \"protocol_type\", \"service\", \"flag\",\n",
        "\"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
        "\"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\n",
        "\"label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QLbxSqTbO9A6"
      },
      "source": [
        "Bộ dữ liệu có dạng như sau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c4NUueQeM6lS",
        "outputId": "07f34cfa-0618-4c7e-92de-c975d3efcc60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "data.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------------+-------+----+---------+---------+----+--------------+------+---+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-------+\n",
            "|duration|protocol_type|service|flag|src_bytes|dst_bytes|land|wrong_fragment|urgent|hot|num_failed_logins|logged_in|num_compromised|root_shell|su_attempted|num_root|num_file_creations|num_shells|num_access_files|num_outbound_cmds|is_host_login|is_guest_login|count|srv_count|serror_rate|srv_serror_rate|rerror_rate|srv_rerror_rate|same_srv_rate|diff_srv_rate|srv_diff_host_rate|dst_host_count|dst_host_srv_count|dst_host_same_srv_rate|dst_host_diff_srv_rate|dst_host_same_src_port_rate|dst_host_srv_diff_host_rate|dst_host_serror_rate|dst_host_srv_serror_rate|dst_host_rerror_rate|dst_host_srv_rerror_rate|  label|\n",
            "+--------+-------------+-------+----+---------+---------+----+--------------+------+---+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-------+\n",
            "|       0|          tcp|   http|  SF|      181|     5450|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    8|        8|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|             9|                 9|                   1.0|                   0.0|                       0.11|                        0.0|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      239|      486|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    8|        8|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|            19|                19|                   1.0|                   0.0|                       0.05|                        0.0|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      235|     1337|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    8|        8|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|            29|                29|                   1.0|                   0.0|                       0.03|                        0.0|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      219|     1337|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    6|        6|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|            39|                39|                   1.0|                   0.0|                       0.03|                        0.0|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      217|     2032|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    6|        6|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|            49|                49|                   1.0|                   0.0|                       0.02|                        0.0|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      217|     2032|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    6|        6|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|            59|                59|                   1.0|                   0.0|                       0.02|                        0.0|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      212|     1940|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    1|        2|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               1.0|             1|                69|                   1.0|                   0.0|                        1.0|                       0.04|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      159|     4087|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    5|        5|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|            11|                79|                   1.0|                   0.0|                       0.09|                       0.04|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      210|      151|   0|             0|     0|  0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    8|        8|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|             8|                89|                   1.0|                   0.0|                       0.12|                       0.04|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "|       0|          tcp|   http|  SF|      212|      786|   0|             0|     0|  1|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    8|        8|        0.0|            0.0|        0.0|            0.0|          1.0|          0.0|               0.0|             8|                99|                   1.0|                   0.0|                       0.12|                       0.05|                 0.0|                     0.0|                 0.0|                     0.0|normal.|\n",
            "+--------+-------------+-------+----+---------+---------+----+--------------+------+---+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xrzUcmjt5jNo"
      },
      "source": [
        "Các nhãn dữ liệu và số lượng tương ứng:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WnJsrZk4iMgc",
        "outputId": "139ed5bb-05c1-4172-ca77-ea01f73e7135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "data.select(\"label\").groupBy(\"label\").count().orderBy(col(\"count\").desc()).show(25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+------+\n",
            "|           label| count|\n",
            "+----------------+------+\n",
            "|          smurf.|280790|\n",
            "|        neptune.|107201|\n",
            "|         normal.| 97278|\n",
            "|           back.|  2203|\n",
            "|          satan.|  1589|\n",
            "|        ipsweep.|  1247|\n",
            "|      portsweep.|  1040|\n",
            "|    warezclient.|  1020|\n",
            "|       teardrop.|   979|\n",
            "|            pod.|   264|\n",
            "|           nmap.|   231|\n",
            "|   guess_passwd.|    53|\n",
            "|buffer_overflow.|    30|\n",
            "|           land.|    21|\n",
            "|    warezmaster.|    20|\n",
            "|           imap.|    12|\n",
            "|        rootkit.|    10|\n",
            "|     loadmodule.|     9|\n",
            "|      ftp_write.|     8|\n",
            "|       multihop.|     7|\n",
            "|            phf.|     4|\n",
            "|           perl.|     3|\n",
            "|            spy.|     2|\n",
            "+----------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mui6N2_WFyWS"
      },
      "source": [
        "`import` các hàm cần thiết từ thư viện `pyspark.ml`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "so4rbYTo6Y7q",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.clustering import KMeansModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fiDjm26D91fT"
      },
      "source": [
        "Trong bộ dữ liệu có những trường không mang giá trị số thực. Ta sẽ tiến hành loại bỏ những trường này và giữ lại những trường có giá trị thực để đưa vào feature.\n",
        "\n",
        "*   Input: Bộ dữ liệu dưới dạng `Dataframe`.\n",
        "*   Output: Bộ dữ liệu cũng dạng `Dataframe` sau khi loại bỏ các trường `protocol_type`, `service`, `flag`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tq-t-8_5iTda",
        "outputId": "38b0f28f-9922-487b-d232-0b2f3fdd154a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "numericOnly = data.drop(\"protocol_type\", \"service\", \"flag\")\n",
        "print(numericOnly.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oWh368lC6pUS"
      },
      "source": [
        "Gộp các trường dữ liệu trong `Dataframe` thành một vector duy nhất, mỗi vector tương ứng với một dòng trong tập dữ liệu.\n",
        "\n",
        "Ta sử dụng transformation `VectorAssembler`, giúp gộp nhiều cột thành một vector, mỗi phần tử của vector tương ứng với một dòng của `Dataframe` ban đầu.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhtbWCZm8bV7",
        "colab": {}
      },
      "source": [
        "assembler = VectorAssembler(inputCols=numericOnly.columns[0:-1], outputCol=\"featureVector\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5D2HrwGTCRpk"
      },
      "source": [
        "Tạo ra một mô hình Kmeans với:\n",
        "\n",
        "*   `setSeed(10)`: Khởi tạo và cố định vị trí trung tâm ban đầu của các cluster.\n",
        "*   `setPredictionCol(\"cluster\")`: Tạo ra cột mới `cluster`, tương ứng với cụm phân loại của các phần tử trong `featureVector`.\n",
        "*   `setFeaturesCol(\"featureVector\")`: Đặt các trường feature của mô hình là `featureVector`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4zPkpEnC8gk8",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans().setSeed(10).setPredictionCol(\"cluster\").setFeaturesCol(\"featureVector\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oDIEmCDxErWa"
      },
      "source": [
        "[Pipeline](https://spark.apache.org/docs/latest/ml-pipeline.html): Một chuỗi các Transformers và Estimators trong một model học máy.\n",
        "\n",
        "*   Các hành động: `assembler` và `kmeans`\n",
        "*   Được thực hiện trên bộ data  `numericOnly`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S9kc5iKhCQRM",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline(stages=[assembler, kmeans]) # A chain of commands\n",
        "pipelineModel = pipeline.fit(numericOnly) # A model after performing KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_dg_H0KBZGRB"
      },
      "source": [
        "Model Kmeans sau khi đã train xong:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I-dP9s7k1aq9",
        "outputId": "7a169071-5028-4008-d4ac-face8d34698e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kmeansModel = pipelineModel.stages[-1] # final stage of pipelineModel\n",
        "print(type(kmeansModel))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.ml.clustering.KMeansModel'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RptZNwU3dMrX"
      },
      "source": [
        "In toạ độ các centers của các cụm:\n",
        "\n",
        "Mặc định của Kmeans model chỉ phân 2 cụm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k3XMV_Pocqcv",
        "outputId": "bfc4990b-8b63-4f23-b551-e46241adad7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "centers = kmeansModel.clusterCenters() # Output: A numpy array of centers\n",
        "print(\"Cluster Centers: \")\n",
        "for center in centers:\n",
        "    print(center)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster Centers: \n",
            "[4.79793956e+01 1.62207883e+03 8.68534183e+02 4.45326100e-05\n",
            " 6.43293794e-03 1.41694668e-05 3.45168212e-02 1.51815716e-04\n",
            " 1.48247035e-01 1.02121372e-02 1.11331525e-04 3.64357718e-05\n",
            " 1.13517671e-02 1.08295211e-03 1.09307315e-04 1.00805635e-03\n",
            " 0.00000000e+00 0.00000000e+00 1.38658354e-03 3.32286248e+02\n",
            " 2.92907143e+02 1.76685418e-01 1.76607809e-01 5.74330999e-02\n",
            " 5.77183920e-02 7.91548844e-01 2.09816404e-02 2.89968625e-02\n",
            " 2.32470732e+02 1.88666046e+02 7.53781203e-01 3.09056111e-02\n",
            " 6.01935529e-01 6.68351484e-03 1.76753957e-01 1.76441622e-01\n",
            " 5.81176268e-02 5.74111170e-02]\n",
            "[2.0000000e+00 6.9337564e+08 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.7000000e+01\n",
            " 3.0000000e+00 7.9000000e-01 6.7000000e-01 2.1000000e-01 3.3000000e-01\n",
            " 5.0000000e-02 3.9000000e-01 0.0000000e+00 2.5500000e+02 3.0000000e+00\n",
            " 1.0000000e-02 9.0000000e-02 2.2000000e-01 0.0000000e+00 1.8000000e-01\n",
            " 6.7000000e-01 5.0000000e-02 3.3000000e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zzbqN5E0ikuI",
        "outputId": "704811f3-15bc-42c4-998b-102d339ae2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "withCluster = pipelineModel.transform(numericOnly)\n",
        "withCluster.select(\"cluster\", \"label\").groupBy(\"cluster\", \"label\").count().orderBy(col(\"cluster\"), col(\"count\").desc()).show(25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------------+------+\n",
            "|cluster|           label| count|\n",
            "+-------+----------------+------+\n",
            "|      0|          smurf.|280790|\n",
            "|      0|        neptune.|107201|\n",
            "|      0|         normal.| 97278|\n",
            "|      0|           back.|  2203|\n",
            "|      0|          satan.|  1589|\n",
            "|      0|        ipsweep.|  1247|\n",
            "|      0|      portsweep.|  1039|\n",
            "|      0|    warezclient.|  1020|\n",
            "|      0|       teardrop.|   979|\n",
            "|      0|            pod.|   264|\n",
            "|      0|           nmap.|   231|\n",
            "|      0|   guess_passwd.|    53|\n",
            "|      0|buffer_overflow.|    30|\n",
            "|      0|           land.|    21|\n",
            "|      0|    warezmaster.|    20|\n",
            "|      0|           imap.|    12|\n",
            "|      0|        rootkit.|    10|\n",
            "|      0|     loadmodule.|     9|\n",
            "|      0|      ftp_write.|     8|\n",
            "|      0|       multihop.|     7|\n",
            "|      0|            phf.|     4|\n",
            "|      0|           perl.|     3|\n",
            "|      0|            spy.|     2|\n",
            "|      1|      portsweep.|     1|\n",
            "+-------+----------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7myCijzh6fAO"
      },
      "source": [
        "##**3. Lựa chọn K phù hợp **\n",
        "\n",
        "**2 clusters rõ ràng là không đủ ở đây. Trong dữ liệu, chúng ta thấy có 23 nhãn được gán, vì vậy số lượng cụm được chia có thế là 23 hoặc thậm chí là nhiều hơn. Thông thường, nhiều giá trị của K sẽ được thử để lựa chọn ra gía trị tốt nhất. Vậy tìm k như thế nào, bao nhiêu?**\n",
        "\n",
        "- Một cụm có thể được coi là tốt nếu mỗi điểm dữ liệu ở gần trung tâm của nó nhất so với các tâm còn lại, trong đó, gần nhất ở đây được xác định bởi khoảng cách Euclide. Đây là một cách đơn giản, phổ biến để đánh giá chất lượng của một cụm, bằng giá trị trung bình của các khoảng cách này trên tất cả các điểm, hoặc đôi khi, giá trị trung bình của bình phương khoảng cách . \n",
        "\n",
        "- KMeansModel cung cấp một phương thức computeCost để tính tổng bình phương khoảng cách và dễ dàng sử dụng để tính bình phương khoảng cách trung bình. Ngoài ra có nhiều cách để tính toán chất lượng của một cụm kmean. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w0biNxLciqhM",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import DataFrame\n",
        "from random import randrange\n",
        "def clusteringScore0(data, k):\n",
        "    assembler = VectorAssembler(inputCols=data.columns[0:-1], outputCol=\"featureVector\")\n",
        "    kmeans = KMeans(seed=1, k=k, predictionCol=\"cluster\", featuresCol=\"featureVector\")\n",
        "    pipeline = Pipeline(stages=[assembler, kmeans])\n",
        "    kmeansModel = pipeline.fit(data).stages[-1]\n",
        "    print(k, kmeansModel.computeCost(assembler.transform(data)) / data.count()) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-dsUbJ_9exLN"
      },
      "source": [
        "Chúng ta sẽ thực hiện tính toán trên số lượng cụm là \"20, 40, 60, 80, 100\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eAduI_stekH0",
        "colab": {}
      },
      "source": [
        "for k in range(20, 160, 20):\n",
        "    clusteringScore0(numericOnly, k)\n",
        "    clusteringScore0(numericOnly, k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lsXZNgF9e839"
      },
      "source": [
        "//Mark Nhận xét về kết quả ở đây, sau khi chạy lại \n",
        "\n",
        "Đề tăng độ chính xác, chúng ta sẽ thêm một số thông số của model K-means. \n",
        "1.   tol: Dung sai hội tụ\n",
        "Đây là tham số cho phép điều khiển lượng chuyển động trung tâm cụm tối thiểu được coi là đáng kể; các giá trị thấp hơn có nghĩa là thuật toán K-mean sẽ cho phép các trọng tâm di chuyển ít hơn\n",
        "2.   maxIter: Số vòng lặp tối đa.\n",
        "\n",
        "Mặc định của thuật toán là `maxIter = 20` và `tol =  1e-4`. Chúng ta sẽ đặt `maxIter = 40` và `tol = 1e-5` trong code \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i3j3NXX9d6Jm",
        "colab": {}
      },
      "source": [
        "def clusteringScore1(data, k):\n",
        "    assembler = VectorAssembler(inputCols=data.columns[0:-1], outputCol=\"featureVector\")\n",
        "    kmeans = KMeans(seed=1, k=k, predictionCol=\"cluster\", featuresCol=\"featureVector\", maxIter=40, tol=1.0e-05) # set số vòng lặp, sai số chấp nhận để dừng vòng lặp\n",
        "    pipeline = Pipeline(stages=[assembler, kmeans])\n",
        "    kmeansModel = pipeline.fit(data).stages[-1]\n",
        "    print(k, kmeansModel.computeCost(assembler.transform(data)) / data.count()) #  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B82u3GONitjH",
        "outputId": "c6496128-caec-4a55-d1f3-df2c404d9df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for k in range(20, 120, 20):\n",
        "    clusteringScore0(numericOnly, k)\n",
        "    clusteringScore1(numericOnly, k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20 70090529.18766987\n",
            "20 70090529.18766987\n",
            "40 34134989.30719846\n",
            "40 34134989.30719846\n",
            "60 32241636.217287987\n",
            "60 32241469.66946356\n",
            "80 31426292.4634663\n",
            "80 31426292.4634663\n",
            "100 29985935.77407783\n",
            "100 26300705.9737499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q0exsHniidQ4",
        "colab": {}
      },
      "source": [
        "//mark Đưa ra nhận xét.\n",
        "Test thử xem git hub đã hoạt động chưa."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2yHPdbIxo1DM"
      },
      "source": [
        "### 3.1 Kỹ thuật Feature Normalization\n",
        "Các điểm dữ liệu đôi khi được đo đạc với những đơn vị khác nhau, m và feet chẳng hạn. Hoặc có hai thành phần (của vector dữ liệu) chênh lệch nhau quá lớn, một thành phần có khoảng giá trị từ 0 đến 1000, thành phần kia chỉ có khoảng giá trị từ 0 đến 1 chẳng hạn. Lúc này, chúng ta cần chuẩn hóa dữ liệu trước khi thực hiện các bước tiếp theo.\n",
        "\n",
        "normalizedi = f eaturei − μi σi\n",
        "\n",
        "trong đó u là trung bình và o là phương sai của dữ liệu \n",
        "\n",
        "Thư viện MLlib cung cấp thư viện `StandardScaler`, dùng để chuẩn hoá dữ liệu, và dễ dàng được thêm vào pipeline, các tham số:\n",
        "1. withStd(default: True)  Scales the data to unit standard deviation.\n",
        "2. withMean(default: False) Centers the data with mean before scaling. It will build a dense output, so take care when applying to sparse input\n",
        "- Một cách tiếp cận khác để xác định độ tốt của các cụm kmean - sử dụng căn bậc hai của tổng phương sai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PzEjv99Ijl1y",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "def clusteringScore2(data, k):\n",
        "  assembler = VectorAssembler(inputCols=data.columns[0:-1], outputCol=\"featureVector\")\n",
        "  scaler = StandardScaler(inputCol=\"featureVector\", outputCol=\"scaledFeatureVector\", withStd=True, withMean=False)\n",
        "  kmeans = KMeans(seed=1, k=k, predictionCol=\"cluster\", featuresCol=\"scaledFeatureVector\", maxIter=40, tol=1.0e-05)\n",
        "  pipeline = Pipeline(stages=[assembler, scaler, kmeans])\n",
        "  pipelineModel = pipeline.fit(data)\n",
        "  kmeansModel = pipelineModel.stages[-1]\n",
        "  print(k, kmeansModel.computeCost(pipelineModel.transform(data)) / data.count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTGrhOrcvIgc",
        "colab_type": "text"
      },
      "source": [
        "Chạy thuật toán với số cụm là \"30, 60, ..., 270\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wsyr0BLNkMyP",
        "outputId": "f44df629-e584-4f1c-f662-30215679908e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for k in range(60, 300, 30):\n",
        "  clusteringScore2(numericOnly, k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60 1.1868969161190808\n",
            "90 0.716842007702905\n",
            "120 0.49734934242366263\n",
            "150 0.3759175320833906\n",
            "180 0.3172011058253099\n",
            "210 0.273636909577068\n",
            "240 0.23059890300407695\n",
            "270 0.20361107540315934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBkLiEHBvIge",
        "colab_type": "text"
      },
      "source": [
        "Nhận xét: \n",
        "\n",
        "\n",
        "*   Giảm cost\n",
        "*   Số cụm càng tăng, chi phí càng giảm => chưa hợp lý(hội tụ)\n",
        "    \n",
        "### 3.2 Categorical Variables\n",
        "Ở phần trên chúng ta đã sử dụng phương pháp `Normalization`, tuy nhiên có nhiều phương pháp nữa có thể áp dụng ở đây. Ở phần đầu của bài toán, chúng ta đã loại bỏ đi 3 tham số vì đó không phải kiểu dạng số, chúng ta sẽ sử dụng một số kỹ thuật để sử dụng 3 tham số này, nâng cao độ chính xác của bài toán. \n",
        "Kỹ thuật sử dụng ở đây sẽ là **one-hot encoding**: \n",
        "Ví dụ với trường protocol_type: có chứa 3 loại là: tcp, udp, hoặc là icmp.\n",
        "Chúng ta có thể biến đổi 3 loại này về:\n",
        "tcp => [1, 0, 0]\n",
        "udp => [0, 1, 0]\n",
        "icmp => [0, 0, 1]\n",
        "\n",
        "Cách triển khai:\n",
        "MLLib cung cấp đủ các thư viện để thực hiện one-hot:\n",
        "     - Đầu tiên chúng ta sử dụng `StringIndexer` để biến các chuỗi `string` thành số 0, 1, 2, 3, .. tương ứng\n",
        "     - Tiếp theo sử dụng `OneHotEncoder` để biến các số này thành vector.\n",
        "Hai giai đoạn này sẽ được sử cho vào 1 `Pipeline`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-MaGZ36GoZB6",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "import math\n",
        "def oneHotPipeline(inputCol):\n",
        "    indexer = StringIndexer(inputCol=inputCol, outputCol=(inputCol + \"_indexed\"))\n",
        "    encoder = OneHotEncoder(inputCol=inputCol + \"_indexed\", outputCol=inputCol + \"_vec\")\n",
        "    pipeline = Pipeline(stages=[indexer, encoder])\n",
        "    return (pipeline, inputCol + \"_vec\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3GismErvp7y",
        "colab_type": "text"
      },
      "source": [
        "//Mark: thêm vào demo ở đây để nhìn rõ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GZt7mjdOqCTv",
        "outputId": "c7f1e97d-6c7e-4b42-bafe-813e63619468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "def clusteringScore3(data, k):\n",
        "    (protoTypeEncoder, protoTypeVecCol) = oneHotPipeline(\"protocol_type\")\n",
        "    (serviceEncoder, serviceVecCol) = oneHotPipeline(\"service\")\n",
        "    (flagEncoder, flagVecCol) = oneHotPipeline(\"flag\")\n",
        "    assembleCols = list(set(data.columns) - set([\"label\", \"protocol_type\", \"service\", \"flag\"])) + list([protoTypeVecCol, serviceVecCol, flagVecCol])\n",
        "    assembler = VectorAssembler(inputCols=assembleCols, outputCol=\"featureVector\")\n",
        "    scaler = StandardScaler(inputCol=\"featureVector\", outputCol=\"scaledFeatureVector\", withStd=True, withMean=False)\n",
        "    kmeans = KMeans(seed=1, k=k, predictionCol=\"cluster\", featuresCol=\"scaledFeatureVector\", maxIter=40, tol=1.0e-05)\n",
        "    pipeline = Pipeline(stages=[protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kmeans])\n",
        "    pipelineModel = pipeline.fit(data)\n",
        "    kmeansModel = pipelineModel.stages[-1]\n",
        "    print(k, kmeansModel.computeCost(pipelineModel.transform(data)) / data.count())\n",
        "\n",
        "for k in range(60, 270, 30):\n",
        "    clusteringScore3(data, k)\n",
        "    numericOnly.unpersist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60 34.32659398810193\n",
            "90 10.102528717704127\n",
            "120 2.9569851351736243\n",
            "150 2.1403963857555337\n",
            "180 1.555682536994971\n",
            "210 1.2852764808975832\n",
            "240 0.9366045728591523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpDgnedqmSvQ",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def entropy(counts):\n",
        "    values = filter(lambda x: x > 0, counts)\n",
        "    n = float(sum(values))\n",
        "    sum_entropy = 0.0\n",
        "    for v in counts:\n",
        "      sum_entropy += -(v/n) * math.log((v/n))\n",
        "    # e = map(lambda v: -(v/n) * math.log((v/n)), values)\n",
        "    # print(sum(e))\n",
        "    return sum_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gD8F6kbO1n-O",
        "colab": {}
      },
      "source": [
        "from itertools import groupby\n",
        "def list_group(group_list):\n",
        "  groups = []\n",
        "  for key, group in groupby(group_list):\n",
        "    groups.append(len(list(group)))\n",
        "  return groups\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B65IGK6XssG2",
        "colab": {}
      },
      "source": [
        "def fitPipeline4(data, k):\n",
        "  (protoTypeEncoder, protoTypeVecCol) = oneHotPipeline(\"protocol_type\")\n",
        "  (serviceEncoder, serviceVecCol) = oneHotPipeline(\"service\")\n",
        "  (flagEncoder, flagVecCol) = oneHotPipeline(\"flag\")\n",
        "  assembleCols = list(set(data.columns) - set([\"label\", \"protocol_type\", \"service\", \"flag\"])) + list([protoTypeVecCol, serviceVecCol, flagVecCol])\n",
        "  assembler = VectorAssembler(inputCols=assembleCols, outputCol=\"featureVector\")\n",
        "  scaler = StandardScaler(inputCol=\"featureVector\", outputCol=\"scaledFeatureVector\", withStd=True, withMean=False)\n",
        "  kmeans = KMeans(seed=1, k=k, predictionCol=\"cluster\", featuresCol=\"scaledFeatureVector\", maxIter=40, tol=1.0e-05)\n",
        "  pipeline = Pipeline(stages=[protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kmeans])\n",
        "  return pipeline.fit(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uYiHXi-_xKFO"
      },
      "source": [
        "**GroupByKey, MapGroups chỉ hỗ trợ trong Spark với Scala, Java. Tuy nhiên trong document của spark có hướng dẫn là python có những hàm mạnh mẽ tương đương, cụ thể ở đây chúng ta sẽ dùng mapGroup, map, sum của itertools**  \n",
        "Hàm dưới đây có chức năng tính entropy của 1 tập dữ liệu, công thức tính sẽ là: \n",
        "Mỗi cluster được phân cụm sẽ gồm nhiều label trùng nhau, tách tưng cluster ra riêng\n",
        "\n",
        "\n",
        "1.   Tính size của từng cluster, \n",
        "2.   Group từng cluster lại thành các labels, với số lần xuất hiện trong cluster\n",
        "3.   `entropy[i] = -(frequence/sum)*log((frequence/sum))`\n",
        "4.   `Score_of_cluster[i] = size[i] * entropy[i] `\n",
        "5.   `Sum(Score_of_cluster[i])`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "spNYqUIsstwp",
        "colab": {}
      },
      "source": [
        "def clusteringScore4(data, k):\n",
        "  pipelineModel = fitPipeline4(data, k)\n",
        "  # Predict cluster for each datum\n",
        "  clusterLabel = pipelineModel.transform(data).select(\"cluster\", \"label\")\n",
        "  labelsInCluster = clusterLabel.rdd.groupByKey().values()\n",
        "  labelCounts = labelsInCluster.map(lambda labels: list_group(labels)).collect()\n",
        "  sum_of_labelcount = 0.0\n",
        "  for t in labelCounts:\n",
        "    sum_of_labelcount += entropy(t)*sum(t)\n",
        "  return sum_of_labelcount / data.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "43E6RUKZ2MbT",
        "outputId": "fdfb94d8-9ca4-47a7-ed69-e7a86a4412d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for k in range(60, 300, 30):\n",
        "  print(clusteringScore4(data, k))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.324306956113726\n",
            "1.1064688883555034\n",
            "0.8790612095658834\n",
            "0.3616672324031876\n",
            "0.28924629592417994\n",
            "0.10476604691418735\n",
            "0.2517526550133862\n",
            "0.22942454180841804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Ux6DeEhzzeT"
      },
      "source": [
        "*Nhìn thấy rằng khi chia 210 cluster có  điểm đánh giá thấp nhất, ta sẽ thực hiện phân tích bất thường với cụm này*\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "Bắt đầu Anomoly Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yO0pcVMkzora",
        "colab": {}
      },
      "source": [
        "pipelineModel = fitPipeline4(data, 180)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgXfY9Hi1y4C",
        "outputId": "4afd16b5-aede-49e1-d46b-7d2a063c464d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "countByClusterLabel = pipelineModel.transform(data).select(\"cluster\", \"label\").groupBy(\"cluster\", \"label\").count().orderBy(\"cluster\", \"label\")\n",
        "countByClusterLabel.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------------+------+\n",
            "|cluster|           label| count|\n",
            "+-------+----------------+------+\n",
            "|      0|         normal.|     9|\n",
            "|      0|          smurf.|280773|\n",
            "|      1|        neptune.|   101|\n",
            "|      1|      portsweep.|     1|\n",
            "|      2|           imap.|     7|\n",
            "|      2|        neptune.|   105|\n",
            "|      3|        neptune.| 36557|\n",
            "|      3|      portsweep.|    13|\n",
            "|      4|        neptune.|   101|\n",
            "|      4|      portsweep.|     4|\n",
            "|      5|        neptune.|    89|\n",
            "|      5|          satan.|     1|\n",
            "|      6|        ipsweep.|     1|\n",
            "|      6|        neptune.|   102|\n",
            "|      6|         normal.|     1|\n",
            "|      6|      portsweep.|     1|\n",
            "|      7|        neptune.|    25|\n",
            "|      8|buffer_overflow.|     6|\n",
            "|      8|      ftp_write.|     4|\n",
            "|      8|     loadmodule.|     1|\n",
            "+-------+----------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "crN9djV74Peo",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "kMeansModel = pipelineModel.stages[-1]\n",
        "centroids = kMeansModel.clusterCenters()\n",
        "clustered = pipelineModel.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PdnnJyYGxwxJ",
        "outputId": "e82ecef1-df55-40d2-f60c-60ae682bb0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "centroids[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 2.43372987e+00, 0.00000000e+00, 2.07710517e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.93369918e-04, 2.37881802e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.93829844e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.40399592e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 9.46901027e-04, 2.74181059e-05,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.57606148e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.57203980e-05,\n",
              "       0.00000000e+00, 2.05843142e+00, 2.02231056e+00, 0.00000000e+00,\n",
              "       2.01966736e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.36212693e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QWLr3hRCxhTx",
        "colab": {}
      },
      "source": [
        "need_order = clustered.select(\"cluster\", \"scaledFeatureVector\").rdd.map(lambda cluster: (Vectors.squared_distance(centroids[cluster[0]], cluster[1]))).collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mTTZwFCk2Bwq",
        "colab": {}
      },
      "source": [
        "need_order.sort(reverse=True)\n",
        "threshold = need_order[100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vM3YehzV5twe",
        "colab": {}
      },
      "source": [
        "originalCols = data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mcFDuhMi9oUO",
        "outputId": "044e0e68-f5c2-4426-a3e6-5b928aebd8b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "originalCols[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'duration'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eL_GsYjW6PDt",
        "colab": {}
      },
      "source": [
        "def distance_cluster(centroids, vec_tor):\n",
        "  return Vectors.squared_distance(centroids, vec_tor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gp4wndWG1igY",
        "colab": {}
      },
      "source": [
        "anomalies = clustered.rdd.filter(lambda row: distance_cluster(centroids[row[\"cluster\"]], row[\"scaledFeatureVector\"]) > threshold).toDF()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WslAd_NC-etr",
        "outputId": "5791a922-91dd-4800-801a-16e6fb66ddfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "anomalies.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(duration=1, protocol_type='tcp', service='ftp', flag='SF', src_bytes=60, dst_bytes=189, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=1, logged_in=0, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=1, srv_count=1, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=151, dst_host_srv_count=47, dst_host_same_srv_rate=0.31, dst_host_diff_srv_rate=0.03, dst_host_same_src_port_rate=0.01, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0, label='normal.', protocol_type_indexed=1.0, protocol_type_vec=SparseVector(2, {1: 1.0}), service_indexed=8.0, service_vec=SparseVector(65, {8: 1.0}), flag_indexed=0.0, flag_vec=SparseVector(10, {0: 1.0}), featureVector=SparseVector(115, {1: 0.31, 3: 0.01, 6: 0.03, 7: 1.0, 10: 151.0, 15: 1.0, 17: 1.0, 18: 47.0, 19: 189.0, 26: 60.0, 30: 1.0, 37: 1.0, 39: 1.0, 48: 1.0, 105: 1.0}), scaledFeatureVector=SparseVector(115, {1: 0.7547, 3: 0.0208, 6: 0.2746, 7: 0.0047, 10: 2.3322, 15: 0.0014, 17: 64.4347, 18: 0.4432, 19: 0.0057, 26: 0.0001, 30: 2.5761, 37: 0.0041, 39: 2.0554, 48: 24.9013, 105: 2.3621}), cluster=144)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}